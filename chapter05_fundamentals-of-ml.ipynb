{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Fundamentals of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Generalization: The goal of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Noisy training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Ambiguous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rare features and spurious correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding white-noise channels or all-zeros channels to MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the same model on MNIST data with noise channels or all-zero channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6953 - loss: 1.0861 - val_accuracy: 0.9014 - val_loss: 0.3242\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2848 - val_accuracy: 0.9472 - val_loss: 0.1799\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.1756 - val_accuracy: 0.9379 - val_loss: 0.2099\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1211 - val_accuracy: 0.9564 - val_loss: 0.1397\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0872 - val_accuracy: 0.9659 - val_loss: 0.1169\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0647 - val_accuracy: 0.9668 - val_loss: 0.1139\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0435 - val_accuracy: 0.9656 - val_loss: 0.1244\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0341 - val_accuracy: 0.9669 - val_loss: 0.1240\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0234 - val_accuracy: 0.9697 - val_loss: 0.1180\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0184 - val_accuracy: 0.9678 - val_loss: 0.1357\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 0.4929 - val_accuracy: 0.9578 - val_loss: 0.1517\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.1298 - val_accuracy: 0.9697 - val_loss: 0.1027\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0819 - val_accuracy: 0.9733 - val_loss: 0.0905\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0578 - val_accuracy: 0.9766 - val_loss: 0.0811\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0427 - val_accuracy: 0.9775 - val_loss: 0.0740\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0319 - val_accuracy: 0.9783 - val_loss: 0.0735\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0240 - val_accuracy: 0.9781 - val_loss: 0.0781\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0178 - val_accuracy: 0.9791 - val_loss: 0.0749\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0130 - val_accuracy: 0.9811 - val_loss: 0.0722\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0094 - val_accuracy: 0.9822 - val_loss: 0.0753\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Plotting a validation accuracy comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x177283880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The nature of generalization in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Fitting a MNIST model with randomly shuffled labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1028 - loss: 2.3317 - val_accuracy: 0.1077 - val_loss: 2.3054\n",
      "Epoch 2/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1166 - loss: 2.2980 - val_accuracy: 0.1025 - val_loss: 2.3124\n",
      "Epoch 3/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1276 - loss: 2.2895 - val_accuracy: 0.0994 - val_loss: 2.3178\n",
      "Epoch 4/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1451 - loss: 2.2759 - val_accuracy: 0.0966 - val_loss: 2.3281\n",
      "Epoch 5/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1557 - loss: 2.2609 - val_accuracy: 0.1006 - val_loss: 2.3373\n",
      "Epoch 6/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1733 - loss: 2.2388 - val_accuracy: 0.1001 - val_loss: 2.3510\n",
      "Epoch 7/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1861 - loss: 2.2164 - val_accuracy: 0.1021 - val_loss: 2.3652\n",
      "Epoch 8/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2052 - loss: 2.1884 - val_accuracy: 0.1012 - val_loss: 2.3861\n",
      "Epoch 9/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2210 - loss: 2.1573 - val_accuracy: 0.1024 - val_loss: 2.3916\n",
      "Epoch 10/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2364 - loss: 2.1187 - val_accuracy: 0.0983 - val_loss: 2.4237\n",
      "Epoch 11/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2516 - loss: 2.0887 - val_accuracy: 0.0997 - val_loss: 2.4499\n",
      "Epoch 12/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2695 - loss: 2.0496 - val_accuracy: 0.1003 - val_loss: 2.4843\n",
      "Epoch 13/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2904 - loss: 2.0098 - val_accuracy: 0.0952 - val_loss: 2.4907\n",
      "Epoch 14/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3070 - loss: 1.9704 - val_accuracy: 0.1001 - val_loss: 2.5246\n",
      "Epoch 15/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3254 - loss: 1.9306 - val_accuracy: 0.1016 - val_loss: 2.5626\n",
      "Epoch 16/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3394 - loss: 1.8882 - val_accuracy: 0.0986 - val_loss: 2.5957\n",
      "Epoch 17/100\n",
      "\u001b[1m352/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3569 - loss: 1.8487"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      9\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_train_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1033 - loss: 2.3304 - val_accuracy: 0.1086 - val_loss: 2.3050\n",
      "Epoch 2/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1188 - loss: 2.2972 - val_accuracy: 0.1042 - val_loss: 2.3098\n",
      "Epoch 3/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1292 - loss: 2.2886 - val_accuracy: 0.0984 - val_loss: 2.3192\n",
      "Epoch 4/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1424 - loss: 2.2765 - val_accuracy: 0.1011 - val_loss: 2.3246\n",
      "Epoch 5/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1527 - loss: 2.2592 - val_accuracy: 0.1010 - val_loss: 2.3338\n",
      "Epoch 6/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1712 - loss: 2.2406 - val_accuracy: 0.1024 - val_loss: 2.3455\n",
      "Epoch 7/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1840 - loss: 2.2159 - val_accuracy: 0.1019 - val_loss: 2.3623\n",
      "Epoch 8/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1978 - loss: 2.1925 - val_accuracy: 0.1037 - val_loss: 2.3802\n",
      "Epoch 9/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2160 - loss: 2.1579 - val_accuracy: 0.1002 - val_loss: 2.3938\n",
      "Epoch 10/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2311 - loss: 2.1263 - val_accuracy: 0.1010 - val_loss: 2.4196\n",
      "Epoch 11/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2499 - loss: 2.0942 - val_accuracy: 0.1005 - val_loss: 2.4356\n",
      "Epoch 12/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2688 - loss: 2.0560 - val_accuracy: 0.1029 - val_loss: 2.4684\n",
      "Epoch 13/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2847 - loss: 2.0208 - val_accuracy: 0.1038 - val_loss: 2.4907\n",
      "Epoch 14/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3025 - loss: 1.9800 - val_accuracy: 0.1016 - val_loss: 2.5334\n",
      "Epoch 15/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3200 - loss: 1.9421 - val_accuracy: 0.1036 - val_loss: 2.5517\n",
      "Epoch 16/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3341 - loss: 1.9044 - val_accuracy: 0.1028 - val_loss: 2.5916\n",
      "Epoch 17/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3514 - loss: 1.8649 - val_accuracy: 0.0987 - val_loss: 2.6428\n",
      "Epoch 18/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3673 - loss: 1.8240 - val_accuracy: 0.1018 - val_loss: 2.6587\n",
      "Epoch 19/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3862 - loss: 1.7791 - val_accuracy: 0.1002 - val_loss: 2.7041\n",
      "Epoch 20/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3982 - loss: 1.7456 - val_accuracy: 0.1001 - val_loss: 2.7330\n",
      "Epoch 21/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4137 - loss: 1.7105 - val_accuracy: 0.1042 - val_loss: 2.7729\n",
      "Epoch 22/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4306 - loss: 1.6697 - val_accuracy: 0.1020 - val_loss: 2.8393\n",
      "Epoch 23/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4429 - loss: 1.6304 - val_accuracy: 0.1013 - val_loss: 2.8546\n",
      "Epoch 24/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4625 - loss: 1.5866 - val_accuracy: 0.1023 - val_loss: 2.8960\n",
      "Epoch 25/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4718 - loss: 1.5521 - val_accuracy: 0.1045 - val_loss: 2.9677\n",
      "Epoch 26/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4839 - loss: 1.5262 - val_accuracy: 0.0998 - val_loss: 3.0015\n",
      "Epoch 27/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4979 - loss: 1.4864 - val_accuracy: 0.1021 - val_loss: 3.0566\n",
      "Epoch 28/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5060 - loss: 1.4618 - val_accuracy: 0.1023 - val_loss: 3.1034\n",
      "Epoch 29/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 1.4158 - val_accuracy: 0.0990 - val_loss: 3.1599\n",
      "Epoch 30/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 1.3960 - val_accuracy: 0.0994 - val_loss: 3.2043\n",
      "Epoch 31/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 1.3658 - val_accuracy: 0.1024 - val_loss: 3.2785\n",
      "Epoch 32/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5542 - loss: 1.3324 - val_accuracy: 0.1011 - val_loss: 3.2912\n",
      "Epoch 33/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 1.2990 - val_accuracy: 0.1025 - val_loss: 3.3685\n",
      "Epoch 34/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5779 - loss: 1.2638 - val_accuracy: 0.0984 - val_loss: 3.4260\n",
      "Epoch 35/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5848 - loss: 1.2450 - val_accuracy: 0.0997 - val_loss: 3.4725\n",
      "Epoch 36/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 1.2085 - val_accuracy: 0.1007 - val_loss: 3.5333\n",
      "Epoch 37/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 1.1935 - val_accuracy: 0.1004 - val_loss: 3.6067\n",
      "Epoch 38/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 1.1727 - val_accuracy: 0.1034 - val_loss: 3.6263\n",
      "Epoch 39/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6222 - loss: 1.1393 - val_accuracy: 0.0992 - val_loss: 3.6994\n",
      "Epoch 40/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6372 - loss: 1.1088 - val_accuracy: 0.0997 - val_loss: 3.7712\n",
      "Epoch 41/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6387 - loss: 1.0920 - val_accuracy: 0.0980 - val_loss: 3.8373\n",
      "Epoch 42/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6472 - loss: 1.0701 - val_accuracy: 0.1013 - val_loss: 3.9020\n",
      "Epoch 43/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6587 - loss: 1.0436 - val_accuracy: 0.1040 - val_loss: 3.9465\n",
      "Epoch 44/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6655 - loss: 1.0277 - val_accuracy: 0.0997 - val_loss: 4.0052\n",
      "Epoch 45/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6695 - loss: 1.0129 - val_accuracy: 0.1015 - val_loss: 4.0905\n",
      "Epoch 46/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6841 - loss: 0.9808 - val_accuracy: 0.1013 - val_loss: 4.1326\n",
      "Epoch 47/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.9553 - val_accuracy: 0.1011 - val_loss: 4.2181\n",
      "Epoch 48/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.9411 - val_accuracy: 0.1002 - val_loss: 4.2494\n",
      "Epoch 49/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.9162 - val_accuracy: 0.1009 - val_loss: 4.3499\n",
      "Epoch 50/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.9000 - val_accuracy: 0.1010 - val_loss: 4.3888\n",
      "Epoch 51/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8834 - val_accuracy: 0.1026 - val_loss: 4.4636\n",
      "Epoch 52/100\n",
      "\u001b[1m352/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.8622"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_random = model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1034 - loss: 2.3293 - val_accuracy: 0.1001 - val_loss: 2.3073\n",
      "Epoch 2/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1192 - loss: 2.2978 - val_accuracy: 0.0997 - val_loss: 2.3127\n",
      "Epoch 3/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1312 - loss: 2.2894 - val_accuracy: 0.1025 - val_loss: 2.3200\n",
      "Epoch 4/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1449 - loss: 2.2755 - val_accuracy: 0.0992 - val_loss: 2.3224\n",
      "Epoch 5/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1563 - loss: 2.2570 - val_accuracy: 0.1018 - val_loss: 2.3406\n",
      "Epoch 6/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1708 - loss: 2.2394 - val_accuracy: 0.0987 - val_loss: 2.3530\n",
      "Epoch 7/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1869 - loss: 2.2140 - val_accuracy: 0.0997 - val_loss: 2.3641\n",
      "Epoch 8/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2034 - loss: 2.1822 - val_accuracy: 0.1041 - val_loss: 2.3832\n",
      "Epoch 9/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2212 - loss: 2.1518 - val_accuracy: 0.1050 - val_loss: 2.3979\n",
      "Epoch 10/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2380 - loss: 2.1175 - val_accuracy: 0.1027 - val_loss: 2.4172\n",
      "Epoch 11/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2621 - loss: 2.0791 - val_accuracy: 0.0993 - val_loss: 2.4505\n",
      "Epoch 12/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2732 - loss: 2.0426 - val_accuracy: 0.1017 - val_loss: 2.4701\n",
      "Epoch 13/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2923 - loss: 2.0049 - val_accuracy: 0.1011 - val_loss: 2.5120\n",
      "Epoch 14/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3042 - loss: 1.9619 - val_accuracy: 0.0978 - val_loss: 2.5383\n",
      "Epoch 15/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3273 - loss: 1.9212 - val_accuracy: 0.0990 - val_loss: 2.5705\n",
      "Epoch 16/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3446 - loss: 1.8809 - val_accuracy: 0.1019 - val_loss: 2.5944\n",
      "Epoch 17/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3594 - loss: 1.8410 - val_accuracy: 0.1039 - val_loss: 2.6331\n",
      "Epoch 18/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3778 - loss: 1.7981 - val_accuracy: 0.0988 - val_loss: 2.6702\n",
      "Epoch 19/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3941 - loss: 1.7613 - val_accuracy: 0.0992 - val_loss: 2.7112\n",
      "Epoch 20/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4105 - loss: 1.7151 - val_accuracy: 0.1017 - val_loss: 2.7583\n",
      "Epoch 21/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4217 - loss: 1.6811 - val_accuracy: 0.1019 - val_loss: 2.7947\n",
      "Epoch 22/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4346 - loss: 1.6514 - val_accuracy: 0.1035 - val_loss: 2.8505\n",
      "Epoch 23/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4487 - loss: 1.6076 - val_accuracy: 0.1018 - val_loss: 2.8767\n",
      "Epoch 24/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4652 - loss: 1.5745 - val_accuracy: 0.1046 - val_loss: 2.9090\n",
      "Epoch 25/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4810 - loss: 1.5320 - val_accuracy: 0.0994 - val_loss: 2.9627\n",
      "Epoch 26/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4913 - loss: 1.4986 - val_accuracy: 0.1004 - val_loss: 3.0207\n",
      "Epoch 27/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5064 - loss: 1.4609 - val_accuracy: 0.1024 - val_loss: 3.0555\n",
      "Epoch 28/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 1.4256 - val_accuracy: 0.0998 - val_loss: 3.1249\n",
      "Epoch 29/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5307 - loss: 1.4040 - val_accuracy: 0.1032 - val_loss: 3.1727\n",
      "Epoch 30/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 1.3628 - val_accuracy: 0.1028 - val_loss: 3.2201\n",
      "Epoch 31/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5515 - loss: 1.3384 - val_accuracy: 0.0991 - val_loss: 3.2456\n",
      "Epoch 32/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5657 - loss: 1.3030 - val_accuracy: 0.1004 - val_loss: 3.3108\n",
      "Epoch 33/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5756 - loss: 1.2688 - val_accuracy: 0.1003 - val_loss: 3.3745\n",
      "Epoch 34/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5835 - loss: 1.2492 - val_accuracy: 0.0997 - val_loss: 3.4324\n",
      "Epoch 35/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 1.2241 - val_accuracy: 0.1000 - val_loss: 3.4970\n",
      "Epoch 36/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 1.1916 - val_accuracy: 0.1014 - val_loss: 3.5745\n",
      "Epoch 37/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6136 - loss: 1.1661 - val_accuracy: 0.1022 - val_loss: 3.6007\n",
      "Epoch 38/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 1.1343 - val_accuracy: 0.1010 - val_loss: 3.6791\n",
      "Epoch 39/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6313 - loss: 1.1176 - val_accuracy: 0.1002 - val_loss: 3.7418\n",
      "Epoch 40/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6410 - loss: 1.0911 - val_accuracy: 0.0999 - val_loss: 3.8148\n",
      "Epoch 41/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6468 - loss: 1.0695 - val_accuracy: 0.1010 - val_loss: 3.8243\n",
      "Epoch 42/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6579 - loss: 1.0402 - val_accuracy: 0.1003 - val_loss: 3.8793\n",
      "Epoch 43/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6615 - loss: 1.0260 - val_accuracy: 0.0973 - val_loss: 3.9857\n",
      "Epoch 44/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.9999 - val_accuracy: 0.1015 - val_loss: 4.0262\n",
      "Epoch 45/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6822 - loss: 0.9781 - val_accuracy: 0.0971 - val_loss: 4.0789\n",
      "Epoch 46/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6853 - loss: 0.9598 - val_accuracy: 0.1006 - val_loss: 4.1365\n",
      "Epoch 47/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.9397 - val_accuracy: 0.1007 - val_loss: 4.2137\n",
      "Epoch 48/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.9143 - val_accuracy: 0.0990 - val_loss: 4.2548\n",
      "Epoch 49/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7125 - loss: 0.8922 - val_accuracy: 0.0990 - val_loss: 4.3392\n",
      "Epoch 50/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7115 - loss: 0.8814 - val_accuracy: 0.1007 - val_loss: 4.3956\n",
      "Epoch 51/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.8568 - val_accuracy: 0.0992 - val_loss: 4.4682\n",
      "Epoch 52/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.8469 - val_accuracy: 0.1022 - val_loss: 4.5383\n",
      "Epoch 53/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.8234 - val_accuracy: 0.0993 - val_loss: 4.5843\n",
      "Epoch 54/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7416 - loss: 0.8054 - val_accuracy: 0.0978 - val_loss: 4.6725\n",
      "Epoch 55/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.7981 - val_accuracy: 0.0990 - val_loss: 4.7509\n",
      "Epoch 56/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.7826 - val_accuracy: 0.0986 - val_loss: 4.7602\n",
      "Epoch 57/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7567 - loss: 0.7617 - val_accuracy: 0.0961 - val_loss: 4.8781\n",
      "Epoch 58/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 0.7411 - val_accuracy: 0.0997 - val_loss: 4.9024\n",
      "Epoch 59/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.7282 - val_accuracy: 0.1013 - val_loss: 4.9757\n",
      "Epoch 60/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7740 - loss: 0.7105 - val_accuracy: 0.1012 - val_loss: 5.1160\n",
      "Epoch 61/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.7022 - val_accuracy: 0.1007 - val_loss: 5.1354\n",
      "Epoch 62/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.6847 - val_accuracy: 0.1008 - val_loss: 5.2124\n",
      "Epoch 63/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.6752 - val_accuracy: 0.0972 - val_loss: 5.2779\n",
      "Epoch 64/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.6536 - val_accuracy: 0.0986 - val_loss: 5.3245\n",
      "Epoch 65/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: 0.6442 - val_accuracy: 0.1000 - val_loss: 5.4202\n",
      "Epoch 66/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.6347 - val_accuracy: 0.1013 - val_loss: 5.4771\n",
      "Epoch 67/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8039 - loss: 0.6162 - val_accuracy: 0.0983 - val_loss: 5.5913\n",
      "Epoch 68/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.6005 - val_accuracy: 0.1007 - val_loss: 5.6290\n",
      "Epoch 69/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.5909 - val_accuracy: 0.0983 - val_loss: 5.7018\n",
      "Epoch 70/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.5814 - val_accuracy: 0.0983 - val_loss: 5.7586\n",
      "Epoch 71/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.5740 - val_accuracy: 0.1005 - val_loss: 5.8624\n",
      "Epoch 72/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8237 - loss: 0.5592 - val_accuracy: 0.0998 - val_loss: 5.8970\n",
      "Epoch 73/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.5389 - val_accuracy: 0.0978 - val_loss: 5.9947\n",
      "Epoch 74/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.5397 - val_accuracy: 0.1000 - val_loss: 6.0398\n",
      "Epoch 75/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.5201 - val_accuracy: 0.1009 - val_loss: 6.1140\n",
      "Epoch 76/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.5104 - val_accuracy: 0.0993 - val_loss: 6.2216\n",
      "Epoch 77/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8422 - loss: 0.5056 - val_accuracy: 0.0998 - val_loss: 6.3133\n",
      "Epoch 78/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4980 - val_accuracy: 0.1002 - val_loss: 6.3500\n",
      "Epoch 79/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8467 - loss: 0.4871 - val_accuracy: 0.0996 - val_loss: 6.4426\n",
      "Epoch 80/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8514 - loss: 0.4757 - val_accuracy: 0.0992 - val_loss: 6.5032\n",
      "Epoch 81/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.4618 - val_accuracy: 0.0988 - val_loss: 6.5768\n",
      "Epoch 82/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.4593 - val_accuracy: 0.0970 - val_loss: 6.6647\n",
      "Epoch 83/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.4455 - val_accuracy: 0.1008 - val_loss: 6.7098\n",
      "Epoch 84/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.4403 - val_accuracy: 0.1003 - val_loss: 6.7938\n",
      "Epoch 85/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.4302 - val_accuracy: 0.1000 - val_loss: 6.8860\n",
      "Epoch 86/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.4192 - val_accuracy: 0.1000 - val_loss: 6.9431\n",
      "Epoch 87/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.4174 - val_accuracy: 0.0993 - val_loss: 7.0346\n",
      "Epoch 88/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8734 - loss: 0.4096 - val_accuracy: 0.0984 - val_loss: 7.1269\n",
      "Epoch 89/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3985 - val_accuracy: 0.1003 - val_loss: 7.1436\n",
      "Epoch 90/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.3879 - val_accuracy: 0.0993 - val_loss: 7.2710\n",
      "Epoch 91/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.3748 - val_accuracy: 0.0995 - val_loss: 7.3091\n",
      "Epoch 92/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.3749 - val_accuracy: 0.0998 - val_loss: 7.3981\n",
      "Epoch 93/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.3714 - val_accuracy: 0.0981 - val_loss: 7.4737\n",
      "Epoch 94/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.3644 - val_accuracy: 0.1002 - val_loss: 7.5616\n",
      "Epoch 95/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.3575 - val_accuracy: 0.0991 - val_loss: 7.6170\n",
      "Epoch 96/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3536 - val_accuracy: 0.1022 - val_loss: 7.7165\n",
      "Epoch 97/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.3473 - val_accuracy: 0.0993 - val_loss: 7.8271\n",
      "Epoch 98/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.3365 - val_accuracy: 0.0993 - val_loss: 7.8975\n",
      "Epoch 99/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.3322 - val_accuracy: 0.1015 - val_loss: 7.8976\n",
      "Epoch 100/100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.3313 - val_accuracy: 0.1023 - val_loss: 7.9744\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m val_acc_original \u001b[38;5;241m=\u001b[39m history_original\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 섞인 레이블의 validation accuracy\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m val_acc_random \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# 이전에 학습한 random_train_labels 모델의 history\u001b[39;00m\n\u001b[1;32m     24\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m)  \u001b[38;5;66;03m# 100 epochs\u001b[39;00m\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, val_acc_original, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb-\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation accuracy with original labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# 원본 레이블로 모델 학습\n",
    "from tensorflow import keras  # Ensure keras is imported\n",
    "from tensorflow.keras import layers  # Ensure layers is imported\n",
    "model_original = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model_original.compile(optimizer=\"rmsprop\",\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "history_original = model_original.fit(train_images, train_labels,\n",
    "                                       epochs=100,\n",
    "                                       batch_size=128,\n",
    "                                       validation_split=0.2)\n",
    "\n",
    "# 정확도 비교 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 원본 레이블의 validation accuracy\n",
    "val_acc_original = history_original.history[\"val_accuracy\"]\n",
    "# 섞인 레이블의 validation accuracy\n",
    "val_acc_random = history_random.history[\"val_accuracy\"]  # 이전에 학습한 random_train_labels 모델의 history\n",
    "\n",
    "epochs = range(1, 101)  # 100 epochs\n",
    "plt.plot(epochs, val_acc_original, \"b-\", label=\"Validation accuracy with original labels\")\n",
    "plt.plot(epochs, val_acc_random, \"r--\", label=\"Validation accuracy with shuffled labels\")\n",
    "plt.title(\"Comparison of Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The manifold hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Interpolation as a source of generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Why deep learning works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training data is paramount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Evaluating machine-learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Simple hold-out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Iterated K-fold validation with shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Beating a common-sense baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Things to keep in mind about model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tuning key gradient descent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a MNIST model with an incorrectly high learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The same model with a more appropriate learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging better architecture priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Increasing model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple logistic regression on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Dataset curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Regularizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Reducing the network's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m         results[i, sequence] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m----> 9\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mvectorize_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     12\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     13\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     14\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m ])\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mvectorize_sequences\u001b[1;34m(sequences, dimension)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvectorize_sequences\u001b[39m(sequences, dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(sequences), dimension))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, sequence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sequences):\n\u001b[0;32m      7\u001b[0m         results[i, sequence] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with lower capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with higher capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding L2 weight regularization to the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Different weight regularizers available in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding dropout to the IMDB model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
